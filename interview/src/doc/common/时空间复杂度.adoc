:stem:
== 时间复杂度
表示方法::
 大O符号表示法 -  `T(n) = O(f(n))`

常见的时间复杂度量级有::
* 常数阶O(1)
* 对数阶O(logN)
* 线性阶O(n)
* 线性对数阶O(nlogN)
* 平方阶O(n²)
* 立方阶O(n³)
* K次方阶O(n^k)
* 指数阶(2^n)

上面从上至下依次的时间复杂度越来越大，执行的效率越来越低。

=== 常数阶 `O(1)`
[example]
.常数阶 - O(1)
====
[source,java]
----
int i = 1;
int j = 2;
++i;
j++;
int m = i + j;
----

上述代码在执行的时候，它消耗的时候并不随着某个变量的增长而增长，那么无论这类代码有多长，即使有几万几十万行，都可以用 `O(1)`
来表示它的时间复杂度。
====

理论上哈希表就是 `O(1)` 。因为哈希表是通过哈希函数来映射的，所以拿到一个关键字，用哈希函数转换一下，
就可以直接从表中取出对应的值。和现存数据有多少毫无关系，故而每次执行该操作只需要恒定的时间（当然，实际操作中存在冲突和冲突
解决的机制，不能保证每次取值的时间是完全一样的）。举个现实的例子，比如我的身后有一排柜子，里面有香蕉（代号B），苹果（代号A）
，葡萄（G），现在你说A，我迅速的就把苹果递过来了；你说B，我迅速就把香蕉递过来了。就算你再增加菠萝（P）、火龙果(H)，但是你
说一个代号，我递给你相应的水果这个速度是几乎不会变的。

=== 线性阶 `O(n)`

[example]
.线性阶 - O(n)
====
[source,java]
----
for(i=1; i<=n; ++i)
{
   j = i;
   j++;
}
----
这段代码，for循环里面的代码会执行n遍，因此它消耗的时间是随着 `n` 的变化而变化的，因此这类代码都可以用 `O(n)` 来表示它的时间复杂度。
====

这个就是说随着样本数量的增加，复杂度也随之线性增加。典型的比如数数。如果一个人从1数到100，需要100秒，那么从1到200，基本
上不会小于200秒，所以数数就是一个 `O(n)`  复杂度的事情。一般来说，需要序贯处理的算法的复杂度，都不会低于 `O(n)` 。比如说
，如果我们要设计一个算法从一堆杂乱的考试的卷子里面找出最高的分数，这就需要我们从头到尾看完每一份试卷，显然试卷越多，需要的时
间也越多，这就是一个 `O(n)` 复杂度的算法。

== 对数阶 `O(logN)`
[example]
.对数阶 - O(logN)
====
[source,java]
----
int i = 1;
while(i<n)
{
    i = i * 2;
}
----
从上面代码可以看到，在 `while` 循环里面，每次都将 i 乘以 2，乘完之后，i 距离 n 就越来越近了。我们试着求解一下，
假设循环x次之后，i 就大于 2 了，此时这个循环就退出了，也就是说 stem:[2^x=n]，那么 stem:[x = log2^n]

也就是说当循环 log2^n 次以后，这个代码就结束了。因此这个代码的时间复杂度为：O(logn)
====

 O(logN)的算法复杂度，典型的比如二分查找。设想一堆试卷，已经从高到底按照分数排列了，我们现在想找到有没有59分的试卷。怎
么办呢？先翻到中间，把试卷堆由中间分成上下两堆，看中间这份是大于还是小于59，如果大于，就留下上面那堆，别的丢掉，如果小于，
就留下下面那堆，丢掉上面。然后按照同样的方法，每次丢一半的试卷，直到丢无可丢为止。

假如有32份试卷，你丢一次，还剩16份 ，丢两次，还剩下8 份，丢三次，就只剩下4份了，可以这么一直丢下去，丢到第五次，就只剩下一
份了 即 stem:[log_2(32) = 5]  也就是我们一次丢一半，总要丢到只有一份的时候才能出结果，如果有n份，那么显然我们就有：
stem:[log_2(n)] 才能得出“找到”或者“没找到”的结果。当然你说你三分查找，每次丢三分之二可不可以？当然也可以，但是算法复杂度在这里是忽略常数的，所以不管以2为底，还是以什么数为底，都统一的写成 `logn` 的形式。

=== 线性对数阶 `O(nlogN)`

线性对数阶O(nlogN) 其实非常容易理解，将时间复杂度为O(logn)的代码循环N遍的话，那么它的时间复杂度就是 n * O(logN)，也就是了O(nlogN)。

[example]
.线性对数阶 - O(nlogN)
====
[source,java]
----
for(m=1; m<n; m++)
{
    i = 1;
    while(i<n)
    {
        i = i * 2;
    }
}
----
====

=== 平方阶 O(stem:[n^2])
平方阶O(n²) 就更容易理解了，如果把 O(n) 的代码再嵌套循环一遍，它的时间复杂度就是 O(n²) 了。

[example]
.平方阶 - O(stem:[n^2])
====
[source,java]
----
for(x=1; i<=n; x++)
{
   for(i=1; i<=n; i++)
    {
       j = i;
       j++;
    }
}
----

这段代码其实就是嵌套了2层n循环，它的时间复杂度就是 O(n*n)，即 O(n²)
如果将其中一层循环的n改成m，即：

[source,java]
----
for(x=1; i<=m; x++)
{
   for(i=1; i<=n; i++)
    {
       j = i;
       j++;
}
}
----
那它的时间复杂度就变成了 O(m*n)

====

计算的复杂度随着样本个数的平方数增长。这个例子在算法里面，就是那一群比较挫的排序，比如冒泡、选择等等。沿着我们刚才的说的那
个试卷的例子，等我们找出最高的分数之后，放在一边另起一堆，然后用同样的方法找第二高的分数，再放到新堆上…… 这样我们做n次，
试卷就按照分数从低到高都排好了。因为有n份试卷，所以这种翻试卷，找最高分的行为，我们要做n次，每次的复杂度是  O(n),那么n个
O(n) 自然就是 O(stem:[n^2])

在比如说构建一个网络，每个点都和其他的点相连。显然，每当我们增加一个点，其实就需要构建这个点和所有现存的点的连线，而现存的点的个数是n，所以每增加1，就需要增加n个连接，那么如果我们增加n个点呢，那这个连接的个数自然也就是 O(stem:[n^2]) 量级了。

无论是翻试卷，还是创建网络，每增加一份试卷，每增加一个点，都需要给算法执行人带来n量级的工作量，这种算法的复杂度就是O(stem:[n^2])

=== 立方阶 O(stem:[n^3])、K次方阶 O(stem:[n^k])
参考上面的O(n²) 去理解就好了，O(n³)相当于三层n循环，其它的类似。

NOTE: 除此之外，其实还有 "平均时间复杂度"、"均摊时间复杂度"、"最坏时间复杂度"、"最好时间复杂度" 的分析方法.

== 空间复杂度

然时间复杂度不是用来计算程序具体耗时的，那么我也应该明白，空间复杂度也不是用来计算程序实际占用的空间的。

空间复杂度是对一个算法在运行过程中临时占用存储空间大小的一个量度，同样反映的是一个趋势，我们用 S(n) 来定义。

空间复杂度比较常用的有::
* O(1)
* O(n)
* O(n²)

=== O(1)
如果算法执行所需要的临时空间不随着某个变量n的大小而变化，即此算法空间复杂度为一个常量，可表示为 O(1)

[example]
.常量空间复杂度
====
[source,java]
----
int i = 1;
int j = 2;
++i;
j++;
int m = i + j;
----
代码中的 i、j、m 所分配的空间都不随着处理数据量变化，因此它的空间复杂度 S(n) = O(1)
====

===  O(n)
[example]
.线性空间复杂度
====
[source,java]
----
int[] m = new int[n]
for(i=1; i<=n; ++i)
{
   j = i;
   j++;
}
----
这段代码中，第一行new了一个数组出来，这个数据占用的大小为n，这段代码的2-6行，虽然有循环，但没有再分配新的空间，因此，
这段代码的空间复杂度主要看第一行即可，即 S(n) = O(n)
====